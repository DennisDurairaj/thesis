\documentclass[../thesis.tex]{subfiles}
\begin{document}
	\section{Test Methodology}
	The experiment evaluates the results of the server by performing benchmark tests. In all the tests, we follow the one-factor-at-a-time experimental design \cite{oaat} to ensure the accuracy and effectiveness of tests.
	
	\subsection{Performance Testing}
	Performance Testing is a type of testing that ensures software applications perform well under certain expected workload. The Features and Functionality supported by a software system is not the only thing to be concerned about. An application's performance parameters such as its response time and reliability matters. The goal of Performance Testing is to eliminate performance bottlenecks.
	\newline

	The goal of Performance Testing is to check a software program's:
 
	\begin{itemize}
		\item Speed - Determines whether the application responds quickly

		\item Scalability - Determines maximum user load the software application can handle.

		\item Stability - Determines if the application is stable under varying loads
	\end{itemize}

	Performance testing also known as as "Perf Testing" is a subclass of performance engineering. It is done to provide developers information about the application regarding speed, stability and scalability. Further, performance testing helps to discover what areas need to be improved before the application goes live. In the absence performance testing, applications are likely to face issues such as: bottlenecks while several users use it simultaneously, inconsistent results across different operating systems and low quality of usability. Performance testing determines whether or not the application meets the requirements of speed, scalability and stability under expected workloads. Applications deployed on the internet with poor performance numbers due to none or poor performance test are likely to gain a bad reputation and fail to meet expected sales goals. Also, applications with high critical usage like space programs or medical tools should be tested throughly to ensure that they function for long period of time without high accuracy.
	\subsection*{Common Performance Problems}
	Most performance problems focus on speed, response time and load time. Speed is usually one of the most important factors of an application. An application that runs slow will lose a lot of potential users. Performance testing is carried out in order to make sure an application runs fast to keep a user's attention and interest. The following is list of common performance problems highlighting how speed is a common factor in many of them:
	\newline
    
	\begin{itemize}
		\item Long load time - Load time is usually the initial time it takes for an application to start up. This should generally be kept as low as possible. While it is impossible to make load time for certain applications in under a minute, it should be kept at least under a few seconds.

		\item Poor response time - Response time is the time taken from when a user enters data into the application to when the application sends a response to that particular input. Usually this should be very fast. 

		\item Poor scalability - An application suffers from poor scalability when it is unable handle an expected number of users or when it cannot accommodate a wide enough range of users. Performance Testing should be carried out to be sure that the application can handle the expected number of users.

		\item Bottlenecking - Bottlenecks are obstacles in the application that lowers overall system performance. It occurs when either coding errors or hardware problems results in a decrease of requests per second under certain loads. Bottlenecking is often caused by one faulty section of code. The key to fixing a bottlenecking issue is to find the section of code that is causing the slow down and try to fix it there. Bottle necking is generally fixed by either fixing poor running processes or adding additional Hardware. Some common performance bottlenecks are CPU utilization, Memory utilization, Network utilization, Operating System limitations, Disk usage.
	\end{itemize}
	\subsection*{Performance Testing Process}
	The philosophy undertaken for performance testing can differ widely but the goal for performance tests remain the same as before. It can help to show that your product's system meets certain pre-characterized performance criteria. Also, it can help compare performance of two software programs. Likewise, it can also help distinguish parts of the software system which lowers the quality of its performance.
	\newline
    
	Below is a generic performance testing process -

	\begin{itemize}
		\item \textbf{Identify your testing environment} - Familiarize with the physical test environment, production environment and which testing equipments are accessible. Comprehend the details of the hardware, software and network settings utilized during testing before you start the testing procedure. It will help testers create more proficient tests.  It will also help in identifying the possible difficulties that testers may face during the performance testing process.

		\item \textbf{Identify the performance acceptance criteria} - This incorporates objectives and limitations for throughput, response and resource allocations.  It is also important to distinguish project success criteria beyond these goals and constraints. Testers should be enabled to set performance criteria and objectives because frequently the project definition will not include a wide enough quantity of performance benchmarks. It is possible that sometimes there may be none at all. If possible, finding a similar application to compare to is an acceptable method to set performance goals.

		\item \textbf{Plan and design performance tests} - Decide how the usage is probably to fluctuate among end users and distinguish key situations to test for all possible use cases. It is necessary to simulate different kinds of end users, design performance test data and outline what metrics will be collected.

		\item \textbf{Configuring the test environment} - Prepare the testing environment before execution. Also, arrange tools and other resources.

		\item \textbf{Implement test design} - Create the performance tests according to the design.

		\item \textbf{Run the tests} - Execute and monitor the tests.

		\item \textbf{Analyze, tune and retest} - Combine, investigate and share test outcomes. Then adjust and test again to check if there is an change in performance. Since improvements usually grow smaller with each test, stop when the CPU reaches bottleneck.
	\end{itemize}
	
	\subsection{Benchmark Test Methodology}
	Benchmark Testing is a kind of testing done to give repeatable set of quantifiable outcomes from which present and future application releases for particular functionality can be baselined or thought on. It is a procedure used to analyze the performance of software systems also known as SUT (System Under Test).
	\paragraph{}
	A benchmark must be repeatable. For example, with each instance of load test, if the response times fluctuates too much, system performance needs to be benchmarked. Response time should be steady amongst various load conditions.
	\paragraph{}
	A benchmark must be quantifiable. For instance, user experience cannot be evaluated in numbers, however time a user spends on a website due to good user interface can be quantified.
	
	\subsection*{Importance of benchmark testing}
	At business level, benchmark testing can be helpful to determine - 

	\begin{itemize}
		\item How well a web-based application is performing with respect to the competitors
		\item It ensures that websites complies with standards and best practices
		\item It enables to evaluate third- party service providers prior to making a contracting decision
		\item Allows to figure out the mistakes to be avoided
		\item How different types of customers experience the response time and availability of a site.
	\end{itemize}
	\subsection{Phases of benchmark testing}
	\subsection*{Planning Phase}
	\begin{itemize}
		\item Identifying and organize standards and requirements
		\item Decide benchmark criteria
		\item Define benchmark test procedures
	\end{itemize}
	\subsection*{Analysis Phase}
	\begin{itemize}
		\item Identify root cause of error to enhance quality
		\item Setting goals for test process
	\end{itemize}
	\subsection*{Integration Phase}
	\begin{itemize}
		\item Share results with concerned individuals and get approval
		\item Establish functional objectives
		\item Define benchmark test process
	\end{itemize}
	\subsection*{Action Phase}
	\begin{itemize}
		\item Design test plan and documentation
		\item Implement actions determined in previous phases and monitor advances
		\item Continously run the process
	\end{itemize}

\end{document}